{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 566S Homework 2\n",
    "## Christopher Ogle\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Algorithm Analysis\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "For this particular assignment we were tasked with creating a Monte Carlo\n",
    "Version of the provided algorithm. For my implementation the time that the\n",
    "algorithm takes to converge is painstakingly slow. Much, much slower than the\n",
    "Gradient Descent algorithm. I sort of expected it to be slow, but I did not\n",
    "expect it to be this slow. Below is a snippet of the critical section of my\n",
    "code and following that is an explanation of why my version is so slow.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  while(run)\n",
    "  {\n",
    "    int cont = 0;\n",
    "    my_diff = 0.0;\n",
    "    printf(\"Currently running on iteration number %d with diff %f\\n\", iteration_number, diff);\n",
    "    diff = 0.0;\n",
    "    iteration_number++;\n",
    "    #pragma omp parallel shared(u, diff) private(i, j, cur, mean, temp_i, temp_j) reduction(+ : cont)\n",
    "    {\n",
    "      srand((int)time(NULL) ^ omp_get_thread_num());\n",
    "      for(i = 1; i < M-1; i++)\n",
    "      {\n",
    "        #pragma omp for\n",
    "        for(j = 1; j < N-1; j++)\n",
    "        {\n",
    "          mean = 0.0;\n",
    "          for(cur = 0; cur < ITER; cur++)\n",
    "          {\n",
    "            temp_i = i;\n",
    "            temp_j = j;\n",
    "            while(1)\n",
    "            {\n",
    "              int direction = rand()%4;\n",
    "              //Go towards the i = 0 row \n",
    "              if(direction == 0)\n",
    "              {\n",
    "                temp_i--;\n",
    "                if(temp_i == 0){mean += 0.0; break;}\n",
    "              }\n",
    "              //Go towards the j = 0 col \n",
    "              else if(direction == 1)\n",
    "              {\n",
    "                temp_j--;\n",
    "                if(temp_j == 0){mean += 100.0; break;}\n",
    "              }\n",
    "              //Go towards the i = M row \n",
    "              else if(direction == 2)\n",
    "              {\n",
    "                temp_i++;\n",
    "                if(temp_i == (M-1)){mean += 100.0; break;}\n",
    "              }\n",
    "              //Go towards the j = N col \n",
    "              else\n",
    "              {\n",
    "                temp_j++;\n",
    "                if(temp_j == (N-1)){mean += 100.0; break;}\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "          double old = u[i][j];\n",
    "          if(iteration_number == 0)\n",
    "          {\n",
    "             u[i][j] = (double) (u[i][j] + mean)/(ITER + 1);\n",
    "          }\n",
    "          else\n",
    "          {\n",
    "            double cur_iter = (double) iteration_number * ITER;\n",
    "            double prev_avg = (double) cur_iter * u[i][j];\n",
    "            u[i][j] = (double) (prev_avg + mean) / (cur_iter + ITER); \n",
    "          }\n",
    "          if( fabs(old - u[i][j])  > epsilon)\n",
    "          {\n",
    "            if( fabs(old - u[i][j]) > my_diff)\n",
    "            {\n",
    "              my_diff = fabs(old - u[i][j]);\n",
    "            }\n",
    "            cont++;\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    #pragma omp critical\n",
    "    {\n",
    "      if(my_diff > diff){diff = my_diff;}\n",
    "    }\n",
    "    }\n",
    "    if(cont == 0){run = 0;}\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "This snippet of code is the main logic behind my algorithm. The reason that this\n",
    "particular piece of code takes so much longer is that we are using a\n",
    "non-deterministic method in order to try and solve the problem. While the\n",
    "gradient descent iterates a definite amounts of times per iteration. The\n",
    "Monte Carlo has no such upper limit. Given that each time through the algorithm\n",
    "it must iterate until it reaches an edge those points in the middle will take\n",
    "a large amount of time in order to complete their journey to the edge. In\n",
    "addition as we increase the size of the graph this only makes the algorithm have\n",
    "to work more. Given that points in the center of graph are further away from the\n",
    "edge it will take much longer to reach the edge. \n",
    "</p>\n",
    "<p>\n",
    "Another thing that really is difficult with this algorithm is that the\n",
    "difference between the previous value at the new value may jump\n",
    "around quite a bit. Because this does not always decrease it can be a real pain\n",
    "to have to run this algorithm. In fact I think if I tried it on a large array like\n",
    "40 by 40, I would most likely overflow the numbers as I am taking the weighted\n",
    "average and calculation how many previous iteration I have taken would be a\n",
    "very large number. One thing that can be done to try and combat this to increase\n",
    "the number of times that you run the algorithm per given iteration. While this\n",
    "helps due to the Law of Large Numbers again you run into the problem of this\n",
    "algorithm, as written, taking a long time, increasing the number of iterations \n",
    "you take in the while loop will nondeterministically increase number of \n",
    "iterations of the algorithm.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/cogle/CSE566_Homework_2/master/Results/Monte/Flucation.PNG\"></img>\n",
    "<i>For a simple 12 by 12 grid with an <b>ITER</b> value of 1000</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Looking at this picture we can see just how much slower this implementation of\n",
    "the algorithm is the small graph takes nearly 13 minutes to complete. In\n",
    "addition the large variance between runs can be seen, which really inhibits one\n",
    "from determining when this algorithm will reach termination. If one has the time\n",
    "and is trying to simulation the randomness of particles then, this method might\n",
    "be the best; however I would prefer the provided code over this algorithm.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "___\n",
    "<center><h3>Data Collection Methodology</h3></center>\n",
    "<p>\n",
    "An important thing to discuss is how data was collected for the following\n",
    "trials. The code that is being used for this problem is the supplied code\n",
    "given to us in the zip file. For this particular test the \n",
    "<b>OMP_NUM_THREADS</b> variable is set to four, further exploration of the\n",
    "how the number of threads affects run time will be looked at later in\n",
    "Problem number 5. Each test will be ran five times with our timing results\n",
    "based off of the timing hook provided in the code (explanation of why in conclusion).\n",
    "All test were run from the school's system. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cogle/20.embed\" height=\"750px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "#CPU events registered, pulled from results folder\n",
    "y0 = [13.530811, 13.134220, 12.986208, 12.984937, 13.180286]\n",
    "y1 = [6.335300, 6.365037, 6.335672, 6.375288, 6.640547]\n",
    "y2 = [3.154183, 3.151281, 3.294024, 3.160028, 3.361889]\n",
    "y3 = [2.982923, 3.163661, 3.316781, 3.000088, 2.992154]\n",
    "y4 = [2.485518, 2.546888, 2.478904, 2.492690, 2.630998]\n",
    "\n",
    "#Each Traces represents a level of optimization\n",
    "trace0 = go.Box(\n",
    "    y=y0,\n",
    "    name = 'No Opt'\n",
    ")\n",
    "trace1 = go.Box(\n",
    "    y=y1,\n",
    "    name = 'Level 1 Opt'\n",
    ")\n",
    "trace2 = go.Box(\n",
    "    y=y2,\n",
    "    name = 'Level 2 Opt'\n",
    ")\n",
    "trace3 = go.Box(\n",
    "    y=y3,\n",
    "    name = 'Level 3 Opt'\n",
    ")\n",
    "trace4 = go.Box(\n",
    "    y=y4,\n",
    "    name = 'Fast Opt'\n",
    ")\n",
    "data = [trace0, trace1, trace2, trace3,trace4]\n",
    "\n",
    "layout=go.Layout(height=750,\n",
    "                 title=\"OpenMP: Time to run vs Optimization\", \n",
    "                 xaxis={'title':'Optimization Level'}, \n",
    "                 yaxis={'title':'Time (sec)'})\n",
    "\n",
    "figure=go.Figure(data=data,layout=layout)\n",
    "py.iplot(figure, filename='OpenMP_graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~cogle/20/\" target=\"_blank\" \n",
    "       title=\"OpenMP: Time to run vs Optimization\" \n",
    "       style=\"display: block; text-align: center;\">\n",
    "       \n",
    "        <img src=\"https://plot.ly/~cogle/20.png\" alt=\"OpenMP: Time to run vs Optimization\" \n",
    "             style=\"max-height:1000\"  \n",
    "             onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"cogle:20\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>OpenMP Optimization Data Analysis</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>\n",
    "Looking at the graph above we can clearly see the trend that as you increase the\n",
    "optimization level the time required to run the algorithm decreases as well too.\n",
    "In the previous assignment we saw that as the optimization level increased, that\n",
    "didn't always correspond in an increase in time.\n",
    "As stated above this particular experiment used 4 threads; one of the things\n",
    "that using 4 threads allows us to do is that we can take advantage assigning\n",
    "each thread to its own core. This allows each thread to take advantage of cache\n",
    "locality when iterating through the for loops. In addition when the compiler\n",
    "optimizes the code each OpenMP thread receives the optimized code. This allows\n",
    "each of the threads to run that optimized code, and results in further speed \n",
    "ups. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "In order to try and determine what lead to such a drop in the speed I compiled\n",
    "the program at optimization level one and then using the following site\n",
    "<a>https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html</a> I applied\n",
    "each one the optimizations to the program and made it. While lots of\n",
    "optimizations decreased the time bit by bit I noticed that the\n",
    "<b>-fcaller-saves</b> optimization decreased the amount of time that the code\n",
    "to run by about 2 seconds from what we see as the average time to run code\n",
    "at Level 1 Optimization.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/cogle/CSE566_Homework_2/master/Results/OptimizationSnip/Timing.PNG\"></img>\n",
    "<p><i>With <b>-fcaller-saves</b></i><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Problem 4</h2>\n",
    "___\n",
    "<center><h3>Data Collection Methodology</h3></center>\n",
    "<p>\n",
    "For this particular problem the data was collected by running the supplied code\n",
    "compiled with optimization level two on the schools system with 4 threads. As \n",
    "before the basis of our  time measurement comes from the in code timing hooks. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cogle/24.embed\" height=\"1000px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.tools import FigureFactory as FF \n",
    "\n",
    "# Create random data with numpy\n",
    "import numpy as np\n",
    "\n",
    "x = ['50', '100', '150' ,'200', '250',\n",
    "     '300', '400', '500' ,'600', '700',\n",
    "     '800', '900', '1000' ,'1100', '1200',\n",
    "     '1300', '1400', '1500']\n",
    "\n",
    "\n",
    "size_50 = [0.014645,0.014547,0.014831,0.014647,0.014675]\n",
    "size_100 = [0.065983,0.066967,0.066720,0.068457,0.064742]\n",
    "size_150 = [0.147041,0.148926,0.155783,0.151992,0.154726]\n",
    "size_200 = [0.336146,0.333026,0.330973,0.333543,0.335950]\n",
    "size_250 = [0.615197,0.621354,0.614993,0.615967,0.612557]\n",
    "size_300 = [0.987381,0.984063,0.965989,0.964826,0.969361]\n",
    "size_400 = [1.948594,1.932207,1.939529,1.938243,1.944792]\n",
    "size_500 = [3.216002,3.201695,3.212385,3.561511,3.218516]\n",
    "size_600 = [4.700759,4.745719,4.745413,4.839352,4.810836]\n",
    "size_700 = [6.468956,6.435122,6.446439,6.355941,6.335129]\n",
    "size_800 = [9.214062,9.086559,8.918791,9.023419,8.997899]\n",
    "size_900 = [10.900986,11.079394,10.756924,10.719667,10.764894]\n",
    "size_1000 = [13.107303,13.938686,13.401571,13.119014,13.222637]\n",
    "size_1100 = [15.861555,15.932275,16.226205,15.939537,16.243901]\n",
    "size_1200 = [19.551888,19.000210,19.613453,19.400393,18.937407]\n",
    "size_1300 = [23.125764,24.162420,23.157251,36.779754,23.727463]\n",
    "size_1400 = [47.653508,39.049947,39.391193,41.874674,47.111895]\n",
    "size_1500 = [57.264617,55.271507,58.151817,57.803165,58.615409]\n",
    "\n",
    "\n",
    "\n",
    "y0 = [np.average(size_50),\n",
    "      np.average(size_100),\n",
    "      np.average(size_150),\n",
    "      np.average(size_200),\n",
    "      np.average(size_250),\n",
    "      np.average(size_300),\n",
    "      np.average(size_400),\n",
    "      np.average(size_500),\n",
    "      np.average(size_600),\n",
    "      np.average(size_700),\n",
    "      np.average(size_800),\n",
    "      np.average(size_900),\n",
    "      np.average(size_1000),\n",
    "      np.average(size_1100),\n",
    "      np.average(size_1200),\n",
    "      np.average(size_1300),\n",
    "      np.average(size_1400),\n",
    "      np.average(size_1500)\n",
    "     ]\n",
    "\n",
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = x,\n",
    "    y = y0,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'r = vM (Default)',\n",
    "    error_y=dict(\n",
    "        type='data',\n",
    "        array=[np.std(size_50), \n",
    "               np.std(size_100),\n",
    "               np.std(size_150),\n",
    "               np.std(size_200),\n",
    "               np.std(size_250),\n",
    "               np.std(size_300),\n",
    "               np.std(size_400),\n",
    "               np.std(size_500),\n",
    "               np.std(size_600),\n",
    "               np.std(size_700),\n",
    "               np.std(size_800),\n",
    "               np.std(size_900),\n",
    "               np.std(size_1000),\n",
    "               np.std(size_1100),\n",
    "               np.std(size_1200),\n",
    "               np.std(size_1300),\n",
    "               np.std(size_1400),\n",
    "               np.std(size_1500)],\n",
    "        visible=True\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace0]\n",
    "layout=go.Layout(height=1000,\n",
    "                 title=\"OpenMP: Time to run vs Array Size\", \n",
    "                 xaxis={'title':'Size of Array (N x N)'}, \n",
    "                 yaxis={'title':'Time(sec)'})\n",
    "\n",
    "figure=go.Figure(data=data,layout=layout)\n",
    "py.iplot(figure, filename='Thread-Timing-Array')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~cogle/24/\" target=\"_blank\" \n",
    "       title=\"OpenMP: Time to run vs Number of Threads\" \n",
    "       style=\"display: block; text-align: center;\">\n",
    "       \n",
    "        <img src=\"https://plot.ly/~cogle/24.png\" alt=\"OpenMP: Time to run vs Number of Threads\" \n",
    "             style=\"max-height:1000\"  \n",
    "             onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"cogle:22\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cogle/26.embed\" height=\"1000px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.tools import FigureFactory as FF \n",
    "\n",
    "# Create random data with numpy\n",
    "import numpy as np\n",
    "\n",
    "x = ['1.0', '1.0^-1', '1.0^-2' ,'1.0^-3', '1.0^-4',\n",
    "     '1.0^-5', '1.0^-6', '1.0^-7' ,'1.0^-8']\n",
    "\n",
    "\n",
    "ep_1 = [0.008293,0.008271,0.008236,0.008312,0.008446]\n",
    "ep_01 = [0.066485,0.065135,0.063764,0.063592,0.064369]\n",
    "ep_001 = [0.416287,0.414127,0.417072,0.413306,0.412400]\n",
    "ep_0001 = [3.464793,3.223525,3.149614,3.224029,3.139216]\n",
    "ep_00001 = [10.518056,10.734608,10.768388,10.229248,10.420260]\n",
    "ep_000001 = [18.615514,19.272254,18.676508,18.874452,18.847971]\n",
    "ep_0000001 = [26.936042,26.929934,27.576725,27.761543,27.062500]\n",
    "ep_00000001 = [38.918818,36.855797,38.565591,36.609836,36.874943]\n",
    "ep_000000001 = [49.057643,50.395065,47.806317,49.886437,49.790664]\n",
    "\n",
    "\n",
    "y0 = [np.average(ep_1),\n",
    "      np.average(ep_01),\n",
    "      np.average(ep_001),\n",
    "      np.average(ep_0001),\n",
    "      np.average(ep_00001),\n",
    "      np.average(ep_000001),\n",
    "      np.average(ep_0000001),\n",
    "      np.average(ep_00000001),\n",
    "      np.average(ep_000000001)\n",
    "     ]\n",
    "\n",
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = x,\n",
    "    y = y0,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'r = vM (Default)',\n",
    "    error_y=dict(\n",
    "        type='data',\n",
    "        array=[np.std(ep_1), \n",
    "               np.std(ep_01),\n",
    "               np.std(ep_001),\n",
    "               np.std(ep_00001),\n",
    "               np.std(ep_000001),\n",
    "               np.std(ep_0000001),\n",
    "               np.std(ep_00000001),\n",
    "               np.std(ep_000000001)\n",
    "              ],\n",
    "        visible=True\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace0]\n",
    "layout=go.Layout(height=1000,\n",
    "                 title=\"OpenMP: Time to run(500x500 4 Threads) vs Epsilon Precision\", \n",
    "                 xaxis={'title':'Value of Epsilon'}, \n",
    "                 yaxis={'title':'Time(sec)'})\n",
    "\n",
    "figure=go.Figure(data=data,layout=layout)\n",
    "py.iplot(figure, filename='Epsilon-Timing-Array')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~cogle/26/\" target=\"_blank\" \n",
    "       title=\"OpenMP: Time to run(500x500 4 Threads) vs Epsilon Precision\" \n",
    "       style=\"display: block; text-align: center;\">\n",
    "       \n",
    "        <img src=\"https://plot.ly/~cogle/26.png\" alt=\"OpenMP: Time to run(500x500 4 Threads) vs Epsilon Precision\" \n",
    "             style=\"max-height:1000\"  \n",
    "             onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"cogle:22\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Problem 5</h2>\n",
    "___\n",
    "<center><h3>Data Collection Methodology</h3></center>\n",
    "<p>\n",
    "For this particular problem the data was collected by running the supplied code\n",
    "compiled with optimization level two on the schools system. As before the basis\n",
    "of our  time measurement comes from the in code timing hooks. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cogle/22.embed\" height=\"1000px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.tools import FigureFactory as FF \n",
    "\n",
    "# Create random data with numpy\n",
    "import numpy as np\n",
    "\n",
    "x = ['1', '2', '3' ,'4', '5',\n",
    "     '6', '7', '8' ,'9', '10',\n",
    "     '11', '12', '13' ,'14', '15',\n",
    "     '16', '17', '18' ,'20', '24',\n",
    "     '28', '32']\n",
    "\n",
    "\n",
    "thread_1 = [10.898600,12.290995,10.954756,11.661482,10.960365]\n",
    "thread_2 = [5.894024,5.890253,5.977245,5.880431,5.882158]\n",
    "thread_3 = [4.176541,4.108237,4.116009,4.180820,4.174366]\n",
    "thread_4 = [3.217831,3.153855,3.329593,3.408588,3.166579]\n",
    "thread_5 = [2.730287,2.711400,2.710112,2.709504,2.642026]\n",
    "thread_6 = [2.334213,2.334365,2.325414,2.451602,2.383726]\n",
    "thread_7 = [2.117244,2.109290,2.112163,2.134355,2.140245]\n",
    "thread_8 = [1.965674,1.970861,1.950640,1.981355,1.984397]\n",
    "thread_9 = [1.897913,1.825782,1.842638,1.822134,1.840135]\n",
    "thread_10 = [1.806611,1.774046,1.744866,1.797151,1.770225]\n",
    "thread_11 = [1.734292,1.682412,1.670571,1.630883,1.689738]\n",
    "thread_12 = [1.657432,1.627978,1.628685,1.635920,1.613842]\n",
    "thread_13 = [144.503488,90.712890,107.803704,145.356468,86.514884]\n",
    "thread_14 = [202.512106,204.469967,203.908372,203.810552,204.043968]\n",
    "thread_15 = [208.167857,207.126849,208.316489,207.540062,209.958652]\n",
    "thread_16 = [213.714671,213.416896,213.798919,213.025954,213.123323]\n",
    "thread_17 = [4.224755,4.252676,3.967282,3.952878,4.039162]\n",
    "thread_18 = [3.990004,3.962726,4.197004,4.090027,3.979533]\n",
    "thread_20 = [4.148234,4.108585,4.097461,4.474365,4.185891]\n",
    "thread_24 = [4.616228,4.576650,4.988805,4.596670,4.568135]\n",
    "thread_28 = [5.245399,5.319254,5.572317,4.870642,5.495162]\n",
    "thread_32 = [5.438613,6.375927,5.940444,5.687882,5.948909]\n",
    "thread_36 = [6.530933,6.799963,6.203396,6.301346,7.821452]\n",
    "\n",
    "\n",
    "y0 = [np.average(thread_1),\n",
    "      np.average(thread_2),\n",
    "      np.average(thread_3),\n",
    "      np.average(thread_4),\n",
    "      np.average(thread_5),\n",
    "      np.average(thread_6),\n",
    "      np.average(thread_7),\n",
    "      np.average(thread_8),\n",
    "      np.average(thread_9),\n",
    "      np.average(thread_10),\n",
    "      np.average(thread_11),\n",
    "      np.average(thread_12),\n",
    "      np.average(thread_13),\n",
    "      np.average(thread_14),\n",
    "      np.average(thread_15),\n",
    "      np.average(thread_16),\n",
    "      np.average(thread_17),\n",
    "      np.average(thread_18),\n",
    "      np.average(thread_20),\n",
    "      np.average(thread_24),\n",
    "      np.average(thread_28),\n",
    "      np.average(thread_32),\n",
    "      np.average(thread_36),\n",
    "     ]\n",
    "\n",
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = x,\n",
    "    y = y0,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'r = vM (Default)',\n",
    "    error_y=dict(\n",
    "        type='data',\n",
    "        array=[np.std(thread_1), \n",
    "               np.std(thread_2),\n",
    "               np.std(thread_3),\n",
    "               np.std(thread_4),\n",
    "               np.std(thread_5),\n",
    "               np.std(thread_6),\n",
    "               np.std(thread_7),\n",
    "               np.std(thread_8),\n",
    "               np.std(thread_8),\n",
    "               np.std(thread_9),\n",
    "               np.std(thread_10),\n",
    "               np.std(thread_11),\n",
    "               np.std(thread_12),\n",
    "               np.std(thread_13),\n",
    "               np.std(thread_14),\n",
    "               np.std(thread_15),\n",
    "               np.std(thread_16),\n",
    "               np.std(thread_17),\n",
    "               np.std(thread_18),\n",
    "               np.std(thread_20),\n",
    "               np.std(thread_24),\n",
    "               np.std(thread_28),\n",
    "               np.std(thread_32),\n",
    "               np.std(thread_36)],\n",
    "        visible=True\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace0]\n",
    "layout=go.Layout(height=1000,\n",
    "                 title=\"OpenMP: Time to run vs Number of Threads\", \n",
    "                 xaxis={'title':'Number of Threads'}, \n",
    "                 yaxis={'title':'Time(sec)'})\n",
    "\n",
    "figure=go.Figure(data=data,layout=layout)\n",
    "py.iplot(figure, filename='Thread-Timing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~cogle/22/\" target=\"_blank\" \n",
    "       title=\"OpenMP: Time to run vs Number of Threads\" \n",
    "       style=\"display: block; text-align: center;\">\n",
    "       \n",
    "        <img src=\"https://plot.ly/~cogle/22.png\" alt=\"OpenMP: Time to run vs Number of Threads\" \n",
    "             style=\"max-height:1000\"  \n",
    "             onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"cogle:22\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>\n",
    "It would appear that as we up until 12 threads we were getting the results that\n",
    "we expected as more threads were added a gradual decrease in time take was\n",
    "achieved. However, when using 13 to 16 threads the number of time it takes\n",
    "skyrockets. Using the <b>lscpu</b> command we can determine that our CPU is a\n",
    "Intel® Xeon® Processor E5-2630 v3 (20M Cache, 2.40 GHz), from the manufacturer's\n",
    "spec sheet we that this has 8 physical cores while supporting 16 threads;\n",
    "through hyperthreading each core has two threads. Using the Scalasca utility I\n",
    "was able to determine which lines the thread was spending most of its time. The\n",
    "screen shot below is from the results I gathered. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/cogle/CSE566_Homework_2/master/Results/NoWaitSnip/NoWait.PNG\"></src>\n",
    "<i>Omp for with nowait 14 Threads</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/cogle/CSE566_Homework_2/master/Results/NoWaitSnip/Wait.PNG\"></img>\n",
    "<i>Omp for without nowait 14 Threads(Code as originally provided)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/cogle/CSE566_Homework_2/master/Results/NoWaitSnip/10_threads.PNG\"><img>\n",
    "<i>Omp for running 10 Threads</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "From the above screenshots we see that indeed making the code not wait did have\n",
    "a significant difference. However, it did not speed it up to the speeds of the\n",
    "ten thread run. So while we were able to speed up the speed a good amount we\n",
    "still see that there is a lot of difference between running the code with 14\n",
    "threads and 10 threads. This leads me to believe that the code is not being\n",
    "optimized well by OpenMP. Another interesting observation is that the poor\n",
    "timing continues up until the maximum number of threads has been reached, and\n",
    "then immediately after that the numbers return a decent level. I would suspect\n",
    "that there is sub-optimal distribution of the work going on with the threads.\n",
    "</p>\n",
    "<p>\n",
    "In addition one of the things that I thought might be hindering the performance\n",
    "is that as we increase the number of threads and each core now shares multiple\n",
    "threads the cache will get written over much more frequently resulting in more\n",
    "cache misses. This doesn't explain the results that we saw, with there being \n",
    "a sharp jump in time, but it could be a contributing factor. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
